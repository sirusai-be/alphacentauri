{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06f2c8c",
   "metadata": {},
   "source": [
    "# Azure OpenAI - AlphaCentauri Project\n",
    "## Step 1: Setting up your Azure & Langchain\n",
    "based on https://learn.deeplearning.ai/courses/building-your-own-database-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f50d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, HTML, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc68452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure OpenAI client configured\n",
      "Endpoint: https://js-alphacentauri-resource.openai.azure.com/\n",
      "Deployment: gpt-4.1-mini\n",
      "API Version: 2025-03-01-preview\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Azure OpenAI Configuration (CORRECT endpoint from Azure Portal)\n",
    "#endpoint = \"https://js-alphacentauri-resource.cognitiveservices.azure.com/\"\n",
    "endpoint =\"https://js-alphacentauri-resource.openai.azure.com/\"\n",
    "deployment = \"gpt-4.1-mini\"\n",
    "v_model = \"gpt-4.1-mini\"\n",
    "api_version = \"2025-03-01-preview\"  # Updated to latest API version for Responses API support\n",
    "\n",
    "# Get API key from environment\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# Create Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI client configured\")\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"Deployment: {deployment}\")\n",
    "print(f\"API Version: {api_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c6a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm working right now, so no need to worry‚Äîeverything will be fine! If you need any help, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# Test the connection\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say hello and tell me you're working! Tell me not to worry, everything will be fine.\",\n",
    "        }\n",
    "    ],\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0d86e",
   "metadata": {},
   "source": [
    "### LangChain Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306807e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create LangChain model\u001b[39;00m\n\u001b[32m      5\u001b[39m model = AzureChatOpenAI(\n\u001b[32m      6\u001b[39m     openai_api_version=api_version,\n\u001b[32m      7\u001b[39m     azure_deployment=deployment,\n\u001b[32m      8\u001b[39m     azure_endpoint=endpoint,\n\u001b[32m      9\u001b[39m     api_key=subscription_key\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.schema'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Create LangChain model\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_deployment=deployment,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key\n",
    ")\n",
    "\n",
    "# Test with LangChain\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Translate 'Hello, how are you?' to French and Spanish.\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d0230",
   "metadata": {},
   "source": [
    "### Streaming Response Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Translate this sentence from English \"\n",
    "    \"to French and Spanish. I like red cars and \"\n",
    "    \"blue houses, but my dog is yellow.\")\n",
    "]   \n",
    "\n",
    "## alternative way to stream the response\n",
    "    # messages=[\n",
    "    #     {\n",
    "    #         \"role\": \"system\",\n",
    "    #         \"content\": \"You are a helpful assistant.\",\n",
    "    #     },\n",
    "    #     {\n",
    "    #         \"role\": \"user\",\n",
    "    #         \"content\": \"Translate this sentence from English \"\n",
    "    # \"to French and Spanish. I like red cars and \"\n",
    "    # \"blue houses, but my dog is yellow.\",\n",
    "    #     }\n",
    "    # ],\n",
    "\n",
    "# Stream the output for better user experience\n",
    "response = client.chat.completions.create(\n",
    "    stream=True,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate this sentence from English \"\n",
    "    \"to French, West Vlaams and Spanish. I like red cars and \"\n",
    "    \"blue houses, but my dog is yellow.\",\n",
    "        }\n",
    "    ],\n",
    "    model=deployment,\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for update in response:\n",
    "    if update.choices:\n",
    "        print(update.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75feb0a",
   "metadata": {},
   "source": [
    "### üîç Debug: Verify Deployment Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "response2 = model.invoke((v_messages))\n",
    "# Pretty print the response as JSON\n",
    "print(json.dumps({\n",
    "    \"content\": response2.content,\n",
    "    \"usage\": response2.usage_metadata,\n",
    "    \"model\": response2.response_metadata.get('model_name', 'N/A')\n",
    "}, indent=2))\n",
    "print (response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb72785",
   "metadata": {},
   "source": [
    "## Step 2: Interacting with CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5af74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain model\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_deployment=deployment,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e243d",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "- baseline model -->\n",
    "- could use \n",
    "  a) fine tuning for sql tasks \n",
    "  b) RAG (database as a source)\n",
    "    - use Langchain agents to connect to SQL Database or CSV file\n",
    "    - via Azure OpenAI Assistants API (function calling + code interpreter) (stateful management + short term memory)\n",
    "    - via Azure OpenAI Fucntion Calling: to perform tasks based on your questions\n",
    "    - Vai Native Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data from the csv file\n",
    "#df = pd.read_csv(\"./data/synthetic_sales_data.csv\").fillna(value = 0)\n",
    "df = pd.read_csv(\"./data/synthetic_sales_data.csv\", sep=\";\").fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file is read and display the first few rows with headers\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head())\n",
    "\n",
    "# Alternative: use this if display() doesn't work\n",
    "# print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed information about the dataset structure\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Rows: {len(df)}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(\"-\" * 80)\n",
    "for i, (col, dtype) in enumerate(zip(df.columns, df.dtypes), 1):\n",
    "    print(f\"{i:2d}. {col:30s} | Type: {dtype}\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb9e86",
   "metadata": {},
   "source": [
    "#### <span style=\"color: red\">SOME ATTENTION REQUIRED</span> \n",
    "create_pandas_dataframe_agent() maak een ‚Äúagent‚Äù die:\n",
    "- Je dataframe (df) kent\n",
    "- Je prompt interpreteert (‚ÄúHow many rows are there?‚Äù)\n",
    "- Daarvoor zelf Python-code schrijft\n",
    "- En die code uitvoert in een ‚ÄúPython REPL‚Äù (read‚Äìeval‚Äìprint-loop) in jouw proces.\n",
    "De ‚ÄúREPL‚Äù is in feite een mini-Python-console binnen jouw proces.\n",
    "En de LLM (of een kwaadaardige prompt) kan daarin eender welke code uitvoeren.\n",
    "Niet alleen veilige dingen zoals len(df), maar ook bijvoorbeeld:\n",
    "\n",
    "--> gezien we controle hebben over de data hier kunnen we **allow_dangerous_code=True** toevoegen, MAAR GEBRUIK DIT NIET IN PRODUCTIE!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm=model,\n",
    "    df=df,\n",
    "    verbose=True, \n",
    "    allow_dangerous_code=True,\n",
    "    max_iterations=30,  # Increase from default 15\n",
    "    max_execution_time=300  # 5 minutes timeout\n",
    ")\n",
    "\n",
    "agent.invoke(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.invoke(\"What can you tell me about the data?\")\n",
    "# agent.invoke(\"List me all the diffrent productlines and their individual summed uprevenue\")\n",
    "agent.invoke(\"List per region which productline sold most units in total and how many units were sold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PROMPT_PREFIX = \"\"\"\n",
    "First set the pandas display options to show all the columns,\n",
    "get the column names, then answer the question.\n",
    "\"\"\"\n",
    "\n",
    "CSV_PROMPT_SUFFIX = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method.\n",
    "Then reflect on the answers of the two methods you did and ask yourself\n",
    "if it answers correctly the original question.\n",
    "If you are not sure, try another method.\n",
    "- If the methods tried do not give the same result,reflect and\n",
    "try again until you have two methods that have the same result.\n",
    "- If you still cannot arrive to a consistent result, say that\n",
    "you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful\n",
    "and thorough response using Markdown.\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,\n",
    "ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.\n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got\n",
    "to the answer on a section that starts with: \"\\n\\nExplanation:\\n\".\n",
    "In the explanation, mention the column names that you used to get\n",
    "to the final answer.\n",
    "\"\"\"\n",
    "\n",
    "#QUESTION = \"How may patients were hospitalized during July 2020\" \n",
    "#\"in Texas, and nationwide as the total of all states?\"\n",
    "SIMPLE_PROMPT = \"\"\"\n",
    "How many patients were hospitalized during July 2020 in Texas, and nationwide as the total of all states?\n",
    "Use the hospitalizedIncrease column.\n",
    "\n",
    "Instructions:\n",
    "1. Filter the data for July 2020 (dates between 2020-07-01 and 2020-07-31)\n",
    "2. Sum the hospitalizedIncrease column for Texas\n",
    "3. Sum the hospitalizedIncrease column for all states\n",
    "4. Provide both answers with a clear explanation\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_PROMPT_SALES = \"\"\"\n",
    "How many toys units are sold in the month of July, regardless the year?\n",
    "\"\"\"\n",
    "\n",
    "QUESTION = \"How may patients were hospitalized during July 2020\" \\\n",
    "\"in Texas, and nationwide as the total of all states?\" \\\n",
    "\"Use the hospitalizedIncrease column\" \n",
    "\n",
    "\n",
    "output = agent.invoke(CSV_PROMPT_PREFIX + SIMPLE_PROMPT_SALES + CSV_PROMPT_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use the complex prompt with reflection (now with increased iteration limit)\n",
    "# Uncomment the line below to try the more thorough approach with validation\n",
    "# agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ed1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the output from the dictionary\n",
    "print(output['output'])\n",
    "\n",
    "# Or display it in markdown for better formatting\n",
    "# display(Markdown(output['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d4c8d3",
   "metadata": {},
   "source": [
    "## Step 3: Connecting to a SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1787153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddaa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the file using Python (works on Windows, Mac, Linux)\n",
    "# url = \"https://covidtracking.com/data/download/all-states-history.csv\"\n",
    "# file_path = \"./data/all-states-history.csv\"\n",
    "\n",
    "# print(f\"Downloading from {url}...\")\n",
    "# urllib.request.urlretrieve(url, file_path)\n",
    "# print(f\"‚úÖ File downloaded to {file_path}\")\n",
    "\n",
    "# # Load the data\n",
    "# df = pd.read_csv(file_path).fillna(value=0)\n",
    "# print(f\"‚úÖ Loaded {len(df)} rows of data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15caa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Path to your SQLite database file\n",
    "# database_file_path = \"./data/test.db\"\n",
    "database_file_path = \"./data/sales_db.db\"\n",
    "\n",
    "# Create an engine to connect to the SQLite database\n",
    "# SQLite only requires the path to the database file\n",
    "engine = create_engine(f'sqlite:///{database_file_path}')\n",
    "# file_url = \"./data/all-states-history.csv\"\n",
    "# df = pd.read_csv(file_url).fillna(value = 0)\n",
    "# df.to_sql(\n",
    "#     'all_states_history',\n",
    "#     con=engine,\n",
    "#     if_exists='replace',\n",
    "#     index=False\n",
    "# )\n",
    "df.to_sql(\n",
    "    'sales_db',\n",
    "    con=engine,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_AGENT_PREFIX = \"\"\"\n",
    "\n",
    "You are an agent designed to interact with a SQL database.\n",
    "## Instructions:\n",
    "- Given an input question, create a syntactically correct {dialect} query\n",
    "to run, then look at the results of the query and return the answer.\n",
    "- Unless the user specifies a specific number of examples they wish to\n",
    "obtain, **ALWAYS** limit your query to at most {top_k} results.\n",
    "- You can order the results by a relevant column to return the most\n",
    "interesting examples in the database.\n",
    "- Never query for all the columns from a specific table, only ask for\n",
    "the relevant columns given the question.\n",
    "- You have access to tools for interacting with the database.\n",
    "- You MUST double check your query before executing it.If you get an error\n",
    "while executing a query,rewrite the query and try again.\n",
    "- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.)\n",
    "to the database.\n",
    "- DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS\n",
    "OF THE CALCULATIONS YOU HAVE DONE.\n",
    "- Your response should be in Markdown. However, **when running  a SQL Query\n",
    "in \"Action Input\", do not include the markdown backticks**.\n",
    "Those are only for formatting the response, not for executing the command.\n",
    "- ALWAYS, as part of your final answer, explain how you got to the answer\n",
    "on a section that starts with: \"Explanation:\". Include the SQL query as\n",
    "part of the explanation section.\n",
    "- If the question does not seem related to the database, just return\n",
    "\"I don\\'t know\" as the answer.\n",
    "- Only use the below tools. Only use the information returned by the\n",
    "below tools to construct your query and final answer.\n",
    "- Do not make up table names, only use the tables returned by any of the\n",
    "tools below.\n",
    "\n",
    "## Tools:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_AGENT_FORMAT_INSTRUCTIONS = \"\"\"\n",
    "\n",
    "## Use the following format:\n",
    "\n",
    "Question: the input question you must answer.\n",
    "Thought: you should always think about what to do.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action.\n",
    "Observation: the result of the action.\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: the final answer to the original input question.\n",
    "\n",
    "Example of Final Answer:\n",
    "<=== Beginning of example\n",
    "\n",
    "Action: query_sql_db\n",
    "Action Input: \n",
    "SELECT TOP (10) [death]\n",
    "FROM covidtracking \n",
    "WHERE state = 'TX' AND date LIKE '2020%'\n",
    "\n",
    "Observation:\n",
    "[(27437.0,), (27088.0,), (26762.0,), (26521.0,), (26472.0,), (26421.0,), (26408.0,)]\n",
    "Thought:I now know the final answer\n",
    "Final Answer: There were 27437 people who died of covid in Texas in 2020.\n",
    "\n",
    "Explanation:\n",
    "I queried the `covidtracking` table for the `death` column where the state\n",
    "is 'TX' and the date starts with '2020'. The query returned a list of tuples\n",
    "with the number of deaths for each day in 2020. To answer the question,\n",
    "I took the sum of all the deaths in the list, which is 27437.\n",
    "I used the following query\n",
    "\n",
    "```sql\n",
    "SELECT [death] FROM covidtracking WHERE state = 'TX' AND date LIKE '2020%'\"\n",
    "```\n",
    "===> End of Example\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain model\n",
    "model2 = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_deployment=deployment,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    temperature = 0,\n",
    "    max_tokens=2000  # Increased to allow proper agent format responses with SQL queries and explanations\n",
    ")\n",
    "db = SQLDatabase.from_uri(f'sqlite:///{database_file_path}')\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4584a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"\"\"How much money did we make?\n",
    "\"\"\"\n",
    "\n",
    "agent_executor_SQL = create_sql_agent(\n",
    "    prefix=MSSQL_AGENT_PREFIX,\n",
    "    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,\n",
    "    llm=model2,\n",
    "    toolkit=toolkit,\n",
    "    top_k=30,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True   # don't crash on parsing errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a529b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = agent_executor_SQL.invoke({\"input\": QUESTION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4936869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Or display it in markdown for better formatting\n",
    "display(Markdown(output_2['input']))\n",
    "display(Markdown(output_2['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493eb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"\"\"Which product line had the highest average profit margin in the West region during 2023, and how much higher was it compared to the lowest one?\n",
    "\"\"\"\n",
    "\n",
    "agent_executor_SQL = create_sql_agent(\n",
    "    prefix=MSSQL_AGENT_PREFIX,\n",
    "    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,\n",
    "    llm=model2,\n",
    "    toolkit=toolkit,\n",
    "    top_k=30,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761618fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_challenge = agent_executor_SQL.invoke({\"input\": QUESTION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(output_challenge['input']))\n",
    "display(Markdown(output_challenge['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122f3f4",
   "metadata": {},
   "source": [
    "## STEP 4. Azure OpenAI Function Calling\n",
    "What is the additional values\n",
    "- provide specific isntructions for finding information \n",
    "- prioritzie queries for precise reulst and desired formats\n",
    "- more control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a205e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "## example of fucntion \n",
    "def get_current_weather(location, unit=\"Celsius\"):\n",
    "    \"\"\"Get the current weather in a given location. \n",
    "    The default unit when not specified is Celsius\"\"\"\n",
    "    if \"merelbeke\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"Merelbeke\", \"country\":\"Belgium\", \"temperature\": \"20\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"antwerpen\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"Antwerpen\", \"country\":\"Belgium\", \"temperature\": \"25\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"las vegas\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"Las Vegas\", \"country\":\"USA\", \"temperature\": \"35\", \"unit\": unit}\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"location\": location, \"country\":\"unknown\", \"temperature\": \"unknown\", \"unit\":  unit}\n",
    "        )\n",
    "\n",
    "get_current_weather(\"Merelbeke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# user prompt\n",
    "weather_messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"What's the weather like in Merelbeke,\n",
    "                   Antwerpen, and Las Vegass?\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#tool definition\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"\"\"Get the current weather in a given\n",
    "                              location.The default unit when not\n",
    "                              specified is Celsius\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The city and state,\n",
    "                                        e.g. San Francisco, CA\"\"\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"default\":\"Celsius\",\n",
    "                        \"enum\": [ \"Fahrenheit\", \"Celsius\"],\n",
    "                        \"description\": \"\"\"The messuring unit for\n",
    "                                          the temperature.\n",
    "                                          If not explicitly specified\n",
    "                                          the default unit is \n",
    "                                          Celsius\"\"\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the OpenAI clietn class\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "\n",
    "#just call the class\n",
    "response = client.chat.completions.create(\n",
    "    model=v_model,\n",
    "    messages=weather_messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\", \n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "print (\"Response message: \\n\" , response_message, \"\\n\\n\" )\n",
    "\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "print (\"TOOLS CALLS: \\n\" , tool_calls , \"\\n\\n\" )\n",
    "\n",
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "} \n",
    "\n",
    "answers = []\n",
    "\n",
    "if tool_calls:\n",
    "   \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\", \"Celsius\")  ## you can see from the function=Fuction that the only argument is location\n",
    "        )\n",
    "        answers.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  \n",
    "    print (\"Answers: \\n\" , answers , \"\\n\\n\" ) \n",
    "    \n",
    "   \n",
    "    def print_arguments(obj):\n",
    "        \"Recursively find and print JSON arguments or content with key/value pairs.\"\n",
    "        if isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                print_arguments(item)\n",
    "        elif isinstance(obj, dict):\n",
    "            # if it looks like a serialized JSON string of arguments/content, try parsing it\n",
    "            for key, val in obj.items():\n",
    "                if key in (\"arguments\", \"content\") and isinstance(val, str) and val.strip().startswith(\"{\"):\n",
    "                    try:\n",
    "                        parsed = json.loads(val)\n",
    "                        for k, v in parsed.items():\n",
    "                            if k == \"unit\":\n",
    "                                print(f\"{k}: {v} \\n\")\n",
    "                                v = 1\n",
    "                            else:\n",
    "                                print(f\"{k}: {v}\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                else:\n",
    "                    print_arguments(val)\n",
    "\n",
    "print_arguments(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sqlalchemy import text\n",
    "\n",
    "def Total_KPI_01(reg, prodline):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT region, productline,  KPI_01\n",
    "        FROM sales_db\n",
    "        WHERE region = '{reg}' AND \n",
    "              productline = '{prodline}'\n",
    "        group by region, productline;\n",
    "        \"\"\"\n",
    "        query = text(query)\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            result = pd.read_sql_query(query, connection)\n",
    "            \n",
    "        if not result.empty:\n",
    "            return result.to_dict('records')\n",
    "        else:\n",
    "            return np.nan\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def sum_profit_cost (reg, prodline):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT region, productline, sum(profit), sum(cost)\n",
    "        FROM sales_db\n",
    "        where region = '{reg}'  AND\n",
    "            productline = '{prodline}'\n",
    "        group by region, productline;\n",
    "        \"\"\"\n",
    "        query = text(query)\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            result = pd.read_sql_query(query, connection)\n",
    "            \n",
    "        if not result.empty:\n",
    "            return result.to_dict('records')\n",
    "        else:\n",
    "            return np.nan\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Total_KPI_01(\"East\",\"Toys\"))\n",
    "\n",
    "print(sum_profit_cost(\"East\",\"Toys\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\" How much what the summed up KPI_01 for Region East and productline Toys?\"\"\"\n",
    "    },\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\" What is the sum of the profits and costs for Region East and productline Clothing\"\"\"\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_sql = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_total_kpi_01_for_region_productline\",\n",
    "            \"description\": \"\"\"Retrieves the sum of the KPI_01 for a specified region and specified productline.\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"reg\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The name of the region\n",
    "                                          (e.g., 'East', 'West').\"\"\"\n",
    "                    },\n",
    "                    \"prodline\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The name of the productline \n",
    "                                          (e.g. 'Toys','Clothing').\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"reg\", \"prodline\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_sum_profit_cost_for_region_productline\",\n",
    "            \"description\": \"\"\"Retrieves the sum of the profits and the costs for a specified region and specified productline\n",
    "                                \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"reg\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The name of the region\n",
    "                                          (e.g., 'East', 'West').\"\"\"\n",
    "                    },\n",
    "                    \"prodline\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The name of the productline \n",
    "                                          (e.g. 'Toys','Clothing').\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"reg\", \"prodline\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94269f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just call the class\n",
    "response = client.chat.completions.create(\n",
    "    model=v_model,\n",
    "    messages=sql_messages,\n",
    "    tools=tools_sql,\n",
    "    tool_choice=\"auto\", \n",
    ")\n",
    "\n",
    "response_sql_message = response.choices[0].message\n",
    "tool_calls = response_sql_message.tool_calls\n",
    "\n",
    "print (tool_calls)\n",
    "sql_answers = []\n",
    "\n",
    "available_functions = {\n",
    "    \"get_total_kpi_01_for_region_productline\": Total_KPI_01,\n",
    "    \"get_sum_profit_cost_for_region_productline\":sum_profit_cost\n",
    "}  \n",
    "\n",
    "if tool_calls:\n",
    "   \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            reg=function_args.get(\"reg\"),\n",
    "            prodline=function_args.get(\"prodline\"),\n",
    "        )\n",
    "        sql_answers.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(function_response),\n",
    "            }\n",
    "        ) \n",
    "    print (\"Answers: \\n\" , sql_answers , \"\\n\\n\" ) \n",
    "    \n",
    "import ast\n",
    "\n",
    "for ans in sql_answers:\n",
    "    content = ast.literal_eval(ans['content'])\n",
    "    \n",
    "    # handle both list and dict formats safely\n",
    "    data = content[0] if isinstance(content, list) else content\n",
    "\n",
    "    print(f\"- Request: {ans['name']}\")\n",
    "    print(f\"- Region: {data.get('Region', '')}\")\n",
    "    print(f\"- ProdLine: {data.get('ProductLine', '')}\")\n",
    "    print(f\"- KPI_01: {data.get('KPI_01', '').replace(',', '.')}\")\n",
    "    print(f\"- Sum of profit: {data.get('sum(profit)', '')}\")\n",
    "    print(f\"- Sum of Cost: {data.get('sum(cost)', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916859ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = client.chat.completions.create(\n",
    "            model=v_model,\n",
    "            messages=sql_messages,\n",
    "        )\n",
    "print (second_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0b3a6",
   "metadata": {},
   "source": [
    "## Step 5: Leveraging Assistants API for SQL Database\n",
    "### Assistants API\n",
    "- behoudt conversatie context - statefull vs de chatcomplete niet\n",
    "- stateful, historiek van interacties\n",
    "- supporteert functions / tool calling\n",
    "- Depreciation note from OpenAI --> responses API (mid 2026)\n",
    "### Code Interpreter\n",
    "- maakt het mogelijk voor de Assistants API om python code te genereren, uit te voeren en veranderen\n",
    "\n",
    "Eigenschap\t|  Assistants API  |  Responses API\n",
    "\n",
    "Stateful (threads & runs)  |  ‚úÖ Ja  |  ‚ùå Nee\n",
    "\n",
    "Contextbeheer  |  Server-side bij OpenAI  |  Client-side door jou\n",
    "\n",
    "Flexibiliteit  |  Minder  |  Veel groter\n",
    "\n",
    "Complexiteit  |  Hoog  |  Lager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Helper\n",
    "from Helper import get_positive_cases_for_state_on_date\n",
    "from Helper import get_hospitalized_increase_for_state_on_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa72172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I) Create assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"\"\"You are an assistant answering questions \n",
    "                  about a Covid dataset.\"\"\",\n",
    "  model=v_model,  # Use the deployment name configured at the top (gpt-4.1-mini)\n",
    "  tools=Helper.tools_sql)\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=v_model,\n",
    "#     instructions=\"You are an assistant answering questions about a Covid dataset.\",\n",
    "#     tools=Helper.tools_sql,\n",
    "#     input=[\n",
    "#         {\"role\": \"user\", \"content\": \"What is the average infection rate by region?\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# II) Create thread\n",
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4020804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# III) Add message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"how many hospitalized people we had in Alaska\n",
    "               the 2021-03-05?\"\"\"\n",
    ")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV) Run assistant on thread\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "status = run.status\n",
    "\n",
    "while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,run_id=run.id\n",
    "    )\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(\n",
    "        int((time.time() - start_time) // 60),\n",
    "        int((time.time() - start_time) % 60))\n",
    "         )\n",
    "    status = run.status\n",
    "    print(f'Status: {status}')\n",
    "    if (status==\"requires_action\"):\n",
    "        available_functions = {\n",
    "            \"get_positive_cases_for_state_on_date\": get_positive_cases_for_state_on_date,\n",
    "            \"get_hospitalized_increase_for_state_on_date\":get_hospitalized_increase_for_state_on_date\n",
    "        }\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                state_abbr=function_args.get(\"state_abbr\"),\n",
    "                specific_date=function_args.get(\"specific_date\"),\n",
    "            )\n",
    "            print(function_response)\n",
    "            print(tool_call.id)\n",
    "            tool_outputs.append(\n",
    "                { \"tool_call_id\": tool_call.id,\n",
    "                 \"output\": str(function_response)\n",
    "                }\n",
    "            )\n",
    "\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id,\n",
    "          tool_outputs = tool_outputs\n",
    "        )\n",
    "\n",
    "\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the error details\n",
    "print(\"Run Status:\", run.status)\n",
    "print(\"\\nFull Run Object:\")\n",
    "print(run)\n",
    "\n",
    "if hasattr(run, 'last_error') and run.last_error:\n",
    "    print(\"\\n‚ùå ERROR DETAILS:\")\n",
    "    print(f\"Error Code: {run.last_error.code}\")\n",
    "    print(f\"Error Message: {run.last_error.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b1f90",
   "metadata": {},
   "source": [
    "###Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"./data/all-states-history.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"\"\"You are an assitant answering questions about\n",
    "                  a Covid dataset.\"\"\",\n",
    "  model=v_model, \n",
    "  tool_resources={\n",
    "        \"code_interpreter\": {\"file_ids\": [file.id]}\n",
    "    } \n",
    "  )## new syntx\n",
    "thread = client.beta.threads.create()\n",
    "print(thread)\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"how many hospitalized people we had in Alaska\n",
    "               the 2021-03-05?\"\"\"\n",
    ")\n",
    "print(message)\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = run.status\n",
    "start_time = time.time()\n",
    "while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(\n",
    "        int((time.time() - start_time) // 60),\n",
    "        int((time.time() - start_time) % 60))\n",
    "         )\n",
    "    status = run.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c87d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
